{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = r\"D:\\Studying\\UoR\\1. Data Mining\\Final_Project\\data\\llama2_finetune_data\\ap_canada.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(input_file_path)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'answer'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Class Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neutral'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sentiment_class(text):\n",
    "    pattern = \"Sentiment:.+\\n\"\n",
    "    match = re.search(pattern, text)\n",
    "    \n",
    "    if match is None:\n",
    "        return None\n",
    "    \n",
    "    return text[match.start():match.end()].split()[-1]\n",
    "    \n",
    "\n",
    "get_sentiment_class(df.answer.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutral', 'Positive', 'Negative'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment_class\"] = df.answer.map(get_sentiment_class)\n",
    "df.sentiment_class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Impartial'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_stance_class(text):\n",
    "    pattern = \"Stance:.+\\n\"\n",
    "    match = re.search(pattern, text)\n",
    "    \n",
    "    if match is None:\n",
    "        return None\n",
    "    \n",
    "    return text[match.start():match.end()].split()[-1]\n",
    "\n",
    "get_stance_class(df.answer.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutral', 'Positive', 'Negative'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"stance_class\"] = df.answer.map(get_sentiment_class)\n",
    "df.stance_class.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sentiment_score(text):\n",
    "    pattern = \"Score:.+\\n\"\n",
    "    matches = [match for match in re.finditer(pattern, text)]\n",
    "    \n",
    "    if matches is None:\n",
    "        return None\n",
    "    \n",
    "    return text[matches[0].start() : matches[0].end()].split()[-1]\n",
    "\n",
    "get_sentiment_score(df.answer.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      10\n",
       "unique      7\n",
       "top       0.0\n",
       "freq        3\n",
       "Name: sentiment_score, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment_score\"] = df.answer.map(get_sentiment_score)\n",
    "df.sentiment_score.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_stance_score(text):\n",
    "    pattern = \"Score:.+\\n\"\n",
    "    matches = [match for match in re.finditer(pattern, text)]\n",
    "    \n",
    "    if matches is None:\n",
    "        return None\n",
    "    \n",
    "    return text[matches[1].start() : matches[1].end()].split()[-1]\n",
    "\n",
    "get_stance_score(df.answer.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      10\n",
       "unique      5\n",
       "top       0.0\n",
       "freq        4\n",
       "Name: stance_score, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"stance_score\"] = df.answer.map(get_stance_score)\n",
    "df.stance_score.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The article presents facts about the performance of both Yuka Saso and Brooke Henderson without expressing positive or negative emotions.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sentiment_reason(text):\n",
    "    pattern = \"(?<=Reason:).+\"\n",
    "    matches = [match for match in re.finditer(pattern, text)]\n",
    "    \n",
    "    if matches is None:\n",
    "        return None\n",
    "    \n",
    "    return text[matches[0].start() : matches[0].end()].strip()\n",
    "\n",
    "get_sentiment_reason(df.answer.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment_reason\"] = df.answer.map(get_sentiment_reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The article neutrally reports on the event, without showing a bias towards or against Canada. It discusses both a Japanese player's success and a Canadian player's struggle.\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_stance_reason(text):\n",
    "    pattern = \"(?<=Reason:).+\"\n",
    "    matches = [match for match in re.finditer(pattern, text)]\n",
    "    \n",
    "    if matches is None:\n",
    "        return None\n",
    "    \n",
    "    return text[matches[1].start() : matches[1].end()].strip()\n",
    "\n",
    "get_stance_reason(df.answer.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"stance_reason\"] = df.answer.map(get_stance_reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>answer</th>\n",
       "      <th>sentiment_class</th>\n",
       "      <th>stance_class</th>\n",
       "      <th>stance_score</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_reason</th>\n",
       "      <th>stance_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a neutral news analyst, assess the sentimen...</td>\n",
       "      <td>1. Sentiment: Positive\\n    * Score: 0.8\\n    ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>The article highlights Canada's victory and qu...</td>\n",
       "      <td>The article focuses on Canada's performance an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>As a neutral news analyst, assess the sentimen...</td>\n",
       "      <td>1. Sentiment: Positive\\n    * Score: 0.7\\n    ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>The article discusses the successful negotiati...</td>\n",
       "      <td>The article focuses on the actions of the Cana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As a neutral news analyst, assess the sentimen...</td>\n",
       "      <td>1. Sentiment: Neutral\\n    * Score: 0.0\\n    *...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The article objectively reports the events of ...</td>\n",
       "      <td>The article neutrally reports on the match, wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As a neutral news analyst, assess the sentimen...</td>\n",
       "      <td>1. Sentiment: Neutral\\n    * Score: 0.0\\n    *...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The article presents facts about the performan...</td>\n",
       "      <td>The article neutrally reports on the event, wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As a neutral news analyst, assess the sentimen...</td>\n",
       "      <td>1. Sentiment: Neutral\\n    * Score: 0.0\\n    *...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The article presents both positive (appointmen...</td>\n",
       "      <td>The article neutrally reports on the changes i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "2  As a neutral news analyst, assess the sentimen...   \n",
       "9  As a neutral news analyst, assess the sentimen...   \n",
       "1  As a neutral news analyst, assess the sentimen...   \n",
       "0  As a neutral news analyst, assess the sentimen...   \n",
       "4  As a neutral news analyst, assess the sentimen...   \n",
       "\n",
       "                                              answer sentiment_class  \\\n",
       "2  1. Sentiment: Positive\\n    * Score: 0.8\\n    ...        Positive   \n",
       "9  1. Sentiment: Positive\\n    * Score: 0.7\\n    ...        Positive   \n",
       "1  1. Sentiment: Neutral\\n    * Score: 0.0\\n    *...         Neutral   \n",
       "0  1. Sentiment: Neutral\\n    * Score: 0.0\\n    *...         Neutral   \n",
       "4  1. Sentiment: Neutral\\n    * Score: 0.0\\n    *...         Neutral   \n",
       "\n",
       "  stance_class stance_score sentiment_score  \\\n",
       "2     Positive          0.6             0.8   \n",
       "9     Positive          0.6             0.7   \n",
       "1      Neutral          0.0             0.0   \n",
       "0      Neutral          0.0             0.0   \n",
       "4      Neutral          0.0             0.0   \n",
       "\n",
       "                                    sentiment_reason  \\\n",
       "2  The article highlights Canada's victory and qu...   \n",
       "9  The article discusses the successful negotiati...   \n",
       "1  The article objectively reports the events of ...   \n",
       "0  The article presents facts about the performan...   \n",
       "4  The article presents both positive (appointmen...   \n",
       "\n",
       "                                       stance_reason  \n",
       "2  The article focuses on Canada's performance an...  \n",
       "9  The article focuses on the actions of the Cana...  \n",
       "1  The article neutrally reports on the match, wi...  \n",
       "0  The article neutrally reports on the event, wi...  \n",
       "4  The article neutrally reports on the changes i...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.llama2.parse_csv import ParseCSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ParseCSV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parser(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>answer</th>\n",
       "      <th>sentiment_class</th>\n",
       "      <th>stance_class</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>stance_score</th>\n",
       "      <th>sentiment_reason</th>\n",
       "      <th>stance_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As a neutral news analyst, assess the sentimen...</td>\n",
       "      <td>1. Sentiment: Neutral\\n    * Score: 0.0\\n    *...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Impartial</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The article presents facts about the performan...</td>\n",
       "      <td>The article neutrally reports on the event, wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As a neutral news analyst, assess the sentimen...</td>\n",
       "      <td>1. Sentiment: Neutral\\n    * Score: 0.0\\n    *...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Impartial</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The article objectively reports the events of ...</td>\n",
       "      <td>The article neutrally reports on the match, wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a neutral news analyst, assess the sentimen...</td>\n",
       "      <td>1. Sentiment: Positive\\n    * Score: 0.8\\n    ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Pro-Canada</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>The article highlights Canada's victory and qu...</td>\n",
       "      <td>The article focuses on Canada's performance an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As a neutral news analyst, assess the sentimen...</td>\n",
       "      <td>1. Sentiment: Negative\\n    * Score: -0.8\\n   ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Against-Canada</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>The article discusses a tragic event and lawsu...</td>\n",
       "      <td>The article implicates a Canadian company, De ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As a neutral news analyst, assess the sentimen...</td>\n",
       "      <td>1. Sentiment: Neutral\\n    * Score: 0.0\\n    *...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Impartial</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The article presents both positive (appointmen...</td>\n",
       "      <td>The article neutrally reports on the changes i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  As a neutral news analyst, assess the sentimen...   \n",
       "1  As a neutral news analyst, assess the sentimen...   \n",
       "2  As a neutral news analyst, assess the sentimen...   \n",
       "3  As a neutral news analyst, assess the sentimen...   \n",
       "4  As a neutral news analyst, assess the sentimen...   \n",
       "\n",
       "                                              answer sentiment_class  \\\n",
       "0  1. Sentiment: Neutral\\n    * Score: 0.0\\n    *...         Neutral   \n",
       "1  1. Sentiment: Neutral\\n    * Score: 0.0\\n    *...         Neutral   \n",
       "2  1. Sentiment: Positive\\n    * Score: 0.8\\n    ...        Positive   \n",
       "3  1. Sentiment: Negative\\n    * Score: -0.8\\n   ...        Negative   \n",
       "4  1. Sentiment: Neutral\\n    * Score: 0.0\\n    *...         Neutral   \n",
       "\n",
       "     stance_class  sentiment_score  stance_score  \\\n",
       "0       Impartial              0.0           0.0   \n",
       "1       Impartial              0.0           0.0   \n",
       "2      Pro-Canada              0.8           0.6   \n",
       "3  Against-Canada             -0.8          -0.6   \n",
       "4       Impartial              0.0           0.0   \n",
       "\n",
       "                                    sentiment_reason  \\\n",
       "0  The article presents facts about the performan...   \n",
       "1  The article objectively reports the events of ...   \n",
       "2  The article highlights Canada's victory and qu...   \n",
       "3  The article discusses a tragic event and lawsu...   \n",
       "4  The article presents both positive (appointmen...   \n",
       "\n",
       "                                       stance_reason  \n",
       "0  The article neutrally reports on the event, wi...  \n",
       "1  The article neutrally reports on the match, wi...  \n",
       "2  The article focuses on Canada's performance an...  \n",
       "3  The article implicates a Canadian company, De ...  \n",
       "4  The article neutrally reports on the changes i...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
